{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b623bc-cd50-439d-a589-de1e5a39d73e",
   "metadata": {},
   "source": [
    "## 💡 마음챙김 (우울증 측정 프로그램)\n",
    "---\n",
    "### ☑️ 소개\n",
    "    이 프로젝트는 10대부터 30대까지의 다양한 우울증 관련 데이터를 기반으로, 사용자의 개인별 특성을 분석하여 맞춤형 우울증 예측 모델을 제공합니다. 인공지능(AI) 기술을 활용해, 각 사용자의 생애 주기와 심리적 특성에 적합한 예측을 수행하며, 이를 통해 보다 정교한 우울증 위험도 평가와 예방 조치를 제시할 수 있습니다. 본 모델은 사용자에게 실시간으로 우울증 가능성을 예측하고, 보다 나은 정신 건강 관리를 돕기 위한 도구로 활용될 수 있습니다.\n",
    "---\n",
    "☑️ 목차\n",
    "1. [☑️ 실습 환경 구성](#실습-환경-구성)\n",
    "2. [☑️ 파이썬 라이브러리](#파이썬-라이브러리)\n",
    "3. [☑️ 각 모델별 점수](#각-모델별-점수)\n",
    "4. [☑️ 결론](#결론)\n",
    "---\n",
    "<a name=\"실습-환경-구성\"></a>\n",
    "### ☑️ 실습 환경 구성\n",
    "- **PC** : 🖥️ MackBook Air 2020, M1 Chip\n",
    "- **MacOS** : 🍎 Sequoia 15.1.1\n",
    "- **Python3** : 🅰️ 3.9.6\n",
    "- **Safari** : 🛜 18.1.1\n",
    "---\n",
    "<a name=\"파이썬-라이브러리\"></a>\n",
    "### ☑️ 파이썬 라이브러리\n",
    "```python\n",
    "#그래프 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# 데이터처리 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 데이터 분배 라이브러리\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# 전처리 라이브러리\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "# 선형모델 라이브러리\n",
    "from skleran.linear_model import LogisticRegression, SGDClassifier\n",
    "# 부스팅 라이브러리\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# 앙상블모델 라이브러리\n",
    "from skleran.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "# 파이프라인 구축\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# 케라스 모델\n",
    "from tensorflow import keras\n",
    "# Earlystopping 모델\n",
    "from keras.callbacks import EarlyStopping\n",
    "```\n",
    "\n",
    "---\n",
    "<a name=\"각-모델별-점수\"></a>\n",
    "### ☑️ 각 모델별 점수\n",
    "    딥러닝 : 입력층(10개) -> 은닉층(16개) -> 은닉층(8개) -> 출력층(1개)\n",
    "    딥러닝 모델 -> 훈련 점수 : 92.1\n",
    "    딥러닝 모델 -> 테스트 점수 : 90.1\n",
    "    머신러닝 (AdaboostClassifier) ->: 훈련 점수 : 97.8\n",
    "    머신러닝 (AdaboostClassifier) ->: 테스트 점수 : 96.0\n",
    "    \n",
    "---\n",
    "<a name=\"결론\"></a>\n",
    "### ☑️ 결론\n",
    "    항상 딥러닝 모델이 유리한 것은 아니다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b6dbdd98-9c3b-4837-9fe9-276a6a9dab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "34e2952f-f89d-45d9-96ca-00d1ff91e44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>나이</th>\n",
       "      <th>학습 압박도</th>\n",
       "      <th>공부 만족도</th>\n",
       "      <th>수면 시간</th>\n",
       "      <th>식습관</th>\n",
       "      <th>자살충동(Y/N)</th>\n",
       "      <th>공부 시간</th>\n",
       "      <th>금전적 스트레스</th>\n",
       "      <th>정신질환 가족력</th>\n",
       "      <th>우울증</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       성별  나이  학습 압박도  공부 만족도              수면 시간        식습관 자살충동(Y/N)  공부 시간  \\\n",
       "0    Male  28     2.0     4.0          7-8 hours   Moderate       Yes      9   \n",
       "1    Male  28     4.0     5.0          5-6 hours    Healthy       Yes      7   \n",
       "2    Male  25     1.0     3.0          5-6 hours  Unhealthy       Yes     10   \n",
       "3    Male  23     1.0     4.0  More than 8 hours  Unhealthy       Yes      7   \n",
       "4  Female  31     1.0     5.0  More than 8 hours    Healthy       Yes      4   \n",
       "\n",
       "   금전적 스트레스 정신질환 가족력  우울증  \n",
       "0         2      Yes   No  \n",
       "1         1      Yes   No  \n",
       "2         4       No  Yes  \n",
       "3         2      Yes   No  \n",
       "4         2      Yes   No  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.read_csv('Depression_Student.csv')\n",
    "student_columns = ['성별', '나이', '학습 압박도', '공부 만족도', '수면 시간', '식습관', '자살충동(Y/N)', \n",
    "                         '공부 시간', '금전적 스트레스', '정신질환 가족력', '우울증']\n",
    "student_data.columns = student_columns\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27e526-f71b-4214-a8af-6ec48154fd3f",
   "metadata": {},
   "source": [
    "### ☑️ 다른 방법\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "numerical_features = ['나이', '학습 압박도', '공부 만족도', '공부 시간', '금전적 스트레스']\n",
    "categorical_features  = ['성별', '수면 시간', '식습관', '자살충동(Y/N)', '정신질환 가족력', '우울증']\n",
    "print(student_data.info())\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OrdinalEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "preprocessed_data = preprocessor.fit_transform(student_data)\n",
    "```\n",
    "### ☑️ 문제\n",
    "    - 공부 시간과 금전적 스트레스는 숫자형 데이터인데, 범주형 데이터로 전처리를 진행하는 오류 발생!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "cc95f3e1-d611-40eb-a1f2-70e15ae1fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>나이</th>\n",
       "      <th>학습 압박도</th>\n",
       "      <th>공부 만족도</th>\n",
       "      <th>수면 시간</th>\n",
       "      <th>식습관</th>\n",
       "      <th>자살충동(Y/N)</th>\n",
       "      <th>공부 시간</th>\n",
       "      <th>금전적 스트레스</th>\n",
       "      <th>정신질환 가족력</th>\n",
       "      <th>우울증</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   성별  나이  학습 압박도  공부 만족도  수면 시간  식습관  자살충동(Y/N)  공부 시간  금전적 스트레스  정신질환 가족력  \\\n",
       "0   1  28     2.0     4.0      1    1          1      9         2         1   \n",
       "1   1  28     4.0     5.0      0    0          1      7         1         1   \n",
       "2   1  25     1.0     3.0      0    2          1     10         4         0   \n",
       "3   1  23     1.0     4.0      3    2          1      7         2         1   \n",
       "4   0  31     1.0     5.0      3    0          1      4         2         1   \n",
       "\n",
       "   우울증  \n",
       "0    0  \n",
       "1    0  \n",
       "2    1  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래서 각각의 데이터에 대해서 전처리하기로 했습니다.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# 남자 : 1 / 여자 : 0\n",
    "student_data['성별'] = le.fit_transform(student_data['성별'])\n",
    "# 5~6시간 : 0 / 7~8시간 : 1 / 5시간 이전 : 2 / 8시간 이상 : 3\n",
    "student_data['수면 시간'] = le.fit_transform(student_data['수면 시간'])\n",
    "# 보통식 : 0, 건강식 : 1, 비건강식 : 2\n",
    "student_data['식습관'] = le.fit_transform(student_data['식습관'])\n",
    "# Yes : 1 / No : 0\n",
    "student_data['자살충동(Y/N)'] = le.fit_transform(student_data['자살충동(Y/N)'])\n",
    "# Yes : 1 / No : 0\n",
    "student_data['정신질환 가족력'] = le.fit_transform(student_data['정신질환 가족력'])\n",
    "# Yes : 1 / No : 0\n",
    "student_data['우울증'] = le.fit_transform(student_data['우울증'])\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "417d4fae-42b6-482f-8473-5b5e4bb66d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 나이에 대한 예측보다는 연령대별 예측이 더 좋을것이라고 생각했습니다.\n",
    "def estimate(data):\n",
    "    if data >= 10 and data < 20: # 10대\n",
    "        return 0\n",
    "    elif data >= 20 and data < 30: # 20대\n",
    "        return 1\n",
    "    elif data >= 30 and data < 40: # 30대\n",
    "        return 2\n",
    "    else: # 나머지\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "505eddc1-3cb5-40bf-b8e7-2b0f2ee93c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>나이</th>\n",
       "      <th>학습 압박도</th>\n",
       "      <th>공부 만족도</th>\n",
       "      <th>수면 시간</th>\n",
       "      <th>식습관</th>\n",
       "      <th>자살충동(Y/N)</th>\n",
       "      <th>공부 시간</th>\n",
       "      <th>금전적 스트레스</th>\n",
       "      <th>정신질환 가족력</th>\n",
       "      <th>우울증</th>\n",
       "      <th>연령대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   성별  나이  학습 압박도  공부 만족도  수면 시간  식습관  자살충동(Y/N)  공부 시간  금전적 스트레스  정신질환 가족력  \\\n",
       "0   1  28     2.0     4.0      1    1          1      9         2         1   \n",
       "1   1  28     4.0     5.0      0    0          1      7         1         1   \n",
       "2   1  25     1.0     3.0      0    2          1     10         4         0   \n",
       "3   1  23     1.0     4.0      3    2          1      7         2         1   \n",
       "4   0  31     1.0     5.0      3    0          1      4         2         1   \n",
       "\n",
       "   우울증  연령대  \n",
       "0    0    1  \n",
       "1    0    1  \n",
       "2    1    1  \n",
       "3    0    1  \n",
       "4    0    2  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 함수를 적용시켜, 각 나이에 맞는 연령대 값을 할당합니다.\n",
    "student_data['연령대'] = student_data['나이'].apply(estimate)\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "9b1b01cc-3ff6-4168-bee2-8c577d8bbe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>학습 압박도</th>\n",
       "      <th>공부 만족도</th>\n",
       "      <th>수면 시간</th>\n",
       "      <th>공부 시간</th>\n",
       "      <th>금전적 스트레스</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>성별</th>\n",
       "      <th>연령대</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>2.791667</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>6.708333</td>\n",
       "      <td>2.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.090278</td>\n",
       "      <td>2.881944</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>5.798611</td>\n",
       "      <td>3.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.955224</td>\n",
       "      <td>3.253731</td>\n",
       "      <td>1.597015</td>\n",
       "      <td>7.044776</td>\n",
       "      <td>2.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3.653846</td>\n",
       "      <td>3.192308</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.835443</td>\n",
       "      <td>3.107595</td>\n",
       "      <td>1.556962</td>\n",
       "      <td>6.474684</td>\n",
       "      <td>2.993671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.072289</td>\n",
       "      <td>2.987952</td>\n",
       "      <td>1.542169</td>\n",
       "      <td>6.686747</td>\n",
       "      <td>2.722892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          학습 압박도    공부 만족도     수면 시간     공부 시간  금전적 스트레스\n",
       "성별 연령대                                                  \n",
       "0  0    2.791667  3.708333  1.541667  6.708333  2.708333\n",
       "   1    3.090278  2.881944  1.388889  5.798611  3.208333\n",
       "   2    2.955224  3.253731  1.597015  7.044776  2.686567\n",
       "1  0    3.653846  3.192308  1.538462  6.500000  2.461538\n",
       "   1    2.835443  3.107595  1.556962  6.474684  2.993671\n",
       "   2    3.072289  2.987952  1.542169  6.686747  2.722892"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성별과, 연령대에 따른 학습 압박도, 공부 만족도, 수면 시간, 공부 시간, 금전적 스트레스의 평균입니다.\n",
    "# 절대적으로 연령별 갈등을 조작하려는게 아니고 단지 데이터에 대한 해석일 뿐입니다.\n",
    "student_data.groupby(['성별', '연령대']).mean()[['학습 압박도', '공부 만족도', '수면 시간', '공부 시간', '금전적 스트레스']]\n",
    "\n",
    "# 성별 : 0->여성 / 1->남성\n",
    "# 연령대 : 0->10대 / 1->20대 / 2->30대\n",
    "# 학습 압박도 : [1, 2, 3, 4, 5]로 구성 -> 압박도가 적을수록 낮은값, 많을수록 높은값 -> 각 압박도별 인원수 : [ 99,  88, 125,  92,  98]\n",
    "# 공부 만족도 : [1, 2, 3, 4, 5]로 구성 -> 만족도가 낮을수록 낮은값, 높을수록 높은값 -> 각 만족도별 인원수 : [ 86, 100, 103, 116,  97]\n",
    "# 수면 시간 : [5~6시간, 7~8시간, 5시간 이하, 8시간 이상] -> 각 수면 시간별 인원수 : [123, 128, 123, 128]\n",
    "# 금전적 스트레스 : [1, 2, 3, 4, 5]로 구성 -> 스트레스가 높을수록 높은값, 낮을수록 낮은값 -> 각 스트레스별 인원수 : [110, 102, 100,  94,  96]\n",
    "# - 데이터가 고르게 분포하고 있는 것을 알 수 있습니다.\n",
    "\n",
    "# 데이터 분석\n",
    "# 여성 10대 : 금전적 스트레스는 낮은 편. 공부 시간이 많고 만족도가 높은편. 그리고 학습 압박도가 낮은편.\n",
    "# 여성 20대 : 금전적 스트레스는 많이 높은 편. 공부 시간이 적고 만족도가 많이 낮은편. 그리고 학습 압박도가 높은편.\n",
    "# 여성 30대 : 금전적 스트레스는 가장 낮은 편. 공부 시간이 많고 만족도가 괜찮은편. 그리고 학습 압박도가 적당한편.\n",
    "\n",
    "# 남성 10대 : 금전적 스트레스는 낮은 편. 공부 시간이 적당하고 만족도가 높은편. 그리고 학습 압박도가 매우 높은편.\n",
    "# 남성 20대 : 금전적 스트레스는 매우 높은 편. 공부 시간이 낮고 만족도가 적당한편. 그리고 학습 압박도가 매우 낮은편.\n",
    "# 남성 30대 : 금전적 스트레스는 적당한 편. 공부 시간이 많고 만족도가 낮은편. 그리고 학습 압박도가 적당한편."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "26980164-6d8b-4309-87b2-88c1f251eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "성별  연령대  자살충동(Y/N)\n",
       "0   0    0            17\n",
       "         1             7\n",
       "    1    0            75\n",
       "         1            69\n",
       "    2    0            28\n",
       "         1            39\n",
       "1   0    0            11\n",
       "         1            15\n",
       "    1    0            75\n",
       "         1            83\n",
       "    2    0            36\n",
       "         1            47\n",
       "Name: 나이, dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자살 충동을 제일 많이 가진 집단은 어딜까요?\n",
    "# 남성 20대가 무려 83회나 되는군요!\n",
    "# 여성 20대도 남성만큼은 아니지만 69회로 여성중에 제일 많군요.\n",
    "student_data.groupby(['성별', '연령대', '자살충동(Y/N)'])['나이'].count()\n",
    "\n",
    "# 위에서 예측했던 데이터를 바탕으로 이번 데이터를 비교해보면, 여성 20대는 금전적 스트레스가 높고 만족도도 낮습니다. 심지어 학습 압박도가 높은 편이니, 자살충동을 느낄 수 있죠!\n",
    "# 그런데, 남성 20대는 금전 스트레스만 높은데, 왜 자살 충동을 가장 많이 느끼는걸까요?\n",
    "# 아마도 여성은 3가지 특성이 많은 영향을 미치고, 남성은 금전적 스트레스가 많은 영향을 미치는 것 같군요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d334a584-b1d5-494e-91f4-685918b36bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우울증을 결과 데이터, 나머지 특성을 훈련데이터로 나누어 먼저 훈련시켜보겠습니다.\n",
    "train_data = student_data[['성별', '연령대', '학습 압박도', '공부 만족도', '수면 시간', '식습관', '자살충동(Y/N)', \n",
    "                         '공부 시간', '금전적 스트레스', '정신질환 가족력']].to_numpy()\n",
    "target_data = student_data['우울증'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "21f12aef-4789-4ee7-b729-b2a2b68380a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 먼저 훈련 데이터와 테스트 데이터를 나눕시다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(train_data,\n",
    "                                                                      target_data,\n",
    "                                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "94401aed-089a-43eb-8baf-b3f51aee8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 부족하지만, 검증 데이터까지 나누죠.\n",
    "train_input, val_input, train_target, val_target = train_test_split(train_input,\n",
    "                                                                    train_target,\n",
    "                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "00582a9f-8b99-46d8-9489-1c56bb3831e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 개수 : (320, 10)\n",
      "검증 데이터 개수 : (81, 10)\n",
      "테스트 데이터 개수 : (101, 10)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터가 320개 밖에 없어서 과소적합이 나올 것 같지만 일단 한번 해보죠\n",
    "print('훈련 데이터 개수 : {}'.format(train_input.shape))\n",
    "print('검증 데이터 개수 : {}'.format(val_input.shape))\n",
    "print('테스트 데이터 개수 : {}'.format(test_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "698d2c21-d2dc-4387-9b60-b9e35f79a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱회귀 훈련데이터 점수 : 0.95625\n",
      "로지스틱회귀 검증데이터 점수 : 0.9753086419753086\n",
      "로지스틱회귀 테스트데이터 점수 : 0.9405940594059405\n"
     ]
    }
   ],
   "source": [
    "# 가장 먼저, 해당 모델은 우울증이냐, 우울증이 아니냐를 묻는 문제이므로 이진 분류를 사용하면 되겠네요.\n",
    "# 이진 분류의 대표주자인 로지스틱 회귀를 사용해보죠.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_input, train_target)\n",
    "print('로지스틱회귀 훈련데이터 점수 : {}'.format(lr.score(train_input, train_target)))\n",
    "print('로지스틱회귀 검증데이터 점수 : {}'.format(lr.score(val_input, val_target)))\n",
    "print('로지스틱회귀 테스트데이터 점수 : {}'.format(lr.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "766fb626-4a79-4179-9e2a-6b2baf4025fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경사하강법 훈련데이터 점수 : 0.95\n",
      "경사하강법 검증데이터 점수 : 0.9629629629629629\n",
      "경사하강법 테스트데이터 점수 : 0.9405940594059405\n"
     ]
    }
   ],
   "source": [
    "# 경사하강법에서 손실을 log_loss로 지정해서 훈련해보죠.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc = SGDClassifier(loss='log_loss')\n",
    "sgdc.fit(train_input, train_target)\n",
    "print('경사하강법 훈련데이터 점수 : {}'.format(sgdc.score(train_input, train_target)))\n",
    "print('경사하강법 검증데이터 점수 : {}'.format(sgdc.score(val_input, val_target)))\n",
    "print('경사하강법 테스트데이터 점수 : {}'.format(sgdc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "45fb6393-ca9e-4a6d-baf0-1489f8b3ccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST 훈련데이터 점수 : 1.0\n",
      "XGBOOST 검증데이터 점수 : 0.8888888888888888\n",
      "XGBOOST 테스트데이터 점수 : 0.8910891089108911\n"
     ]
    }
   ],
   "source": [
    "# 이번에는 XGBoost를 해보죠.\n",
    "from xgboost import XGBClassifier\n",
    "xgbc = XGBClassifier(max_depth=3)\n",
    "xgbc.fit(train_input, train_target)\n",
    "print('XGBOOST 훈련데이터 점수 : {}'.format(xgbc.score(train_input, train_target)))\n",
    "print('XGBOOST 검증데이터 점수 : {}'.format(xgbc.score(val_input, val_target)))\n",
    "print('XGBOOST 테스트데이터 점수 : {}'.format(xgbc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c247f216-9ecc-43d6-89c0-61907ad211b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING 훈련데이터 점수 : 1.0\n",
      "GRADIENT BOOSTING 검증데이터 점수 : 0.8765432098765432\n",
      "GRADIENT BOOSTING 테스트데이터 점수 : 0.900990099009901\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting은 어떨까요?\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdc = GradientBoostingClassifier()\n",
    "gdc.fit(train_input, train_target)\n",
    "print('GRADIENT BOOSTING 훈련데이터 점수 : {}'.format(gdc.score(train_input, train_target)))\n",
    "print('GRADIENT BOOSTING 검증데이터 점수 : {}'.format(gdc.score(val_input, val_target)))\n",
    "print('GRADIENT BOOSTING 테스트데이터 점수 : {}'.format(gdc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ca697880-d151-4310-85bc-9fd7f4168b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost 훈련데이터 점수 : 0.98125\n",
      "AdaBoost 검증데이터 점수 : 0.9506172839506173\n",
      "AdaBoost 테스트데이터 점수 : 0.9504950495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(learning_rate=0.9)\n",
    "abc.fit(train_input, train_target)\n",
    "print('AdaBoost 훈련데이터 점수 : {}'.format(abc.score(train_input, train_target)))\n",
    "print('AdaBoost 검증데이터 점수 : {}'.format(abc.score(val_input, val_target)))\n",
    "print('AdaBoost 테스트데이터 점수 : {}'.format(abc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0e3e76ec-142d-4904-b03f-d8cb13053ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 155, number of negative: 165\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47\n",
      "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484375 -> initscore=-0.062520\n",
      "[LightGBM] [Info] Start training from score -0.062520\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Lightgbm 훈련데이터 점수 : 1.0\n",
      "Lightgbm 검증데이터 점수 : 0.9012345679012346\n",
      "Lightgbm 테스트데이터 점수 : 0.9108910891089109\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbc = LGBMClassifier()\n",
    "lgbc.fit(train_input, train_target)\n",
    "print('Lightgbm 훈련데이터 점수 : {}'.format(lgbc.score(train_input, train_target)))\n",
    "print('Lightgbm 검증데이터 점수 : {}'.format(lgbc.score(val_input, val_target)))\n",
    "print('Lightgbm 테스트데이터 점수 : {}'.format(lgbc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "65567c97-dd86-4e09-b299-13f88d2040a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': np.float64(1.0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 모델중에서는 AdaBoost가 가장 좋은 모습을 보이는군요.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(estimator=AdaBoostClassifier(),\n",
    "                 param_grid={\n",
    "                     'learning_rate':np.arange(0.1, 1.1, 0.1),\n",
    "                 })\n",
    "gs.fit(train_input, train_target)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "21b17363-f9e4-4eb8-8b21-9cf992157947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost 훈련데이터 점수 : 0.9875\n",
      "AdaBoost 검증데이터 점수 : 0.9012345679012346\n",
      "AdaBoost 테스트데이터 점수 : 0.9504950495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 그렇게 만족스러운 점수가 아니군요.\n",
    "abc = AdaBoostClassifier(learning_rate=1.0)\n",
    "abc.fit(train_input, train_target)\n",
    "print('AdaBoost 훈련데이터 점수 : {}'.format(abc.score(train_input, train_target)))\n",
    "print('AdaBoost 검증데이터 점수 : {}'.format(abc.score(val_input, val_target)))\n",
    "print('AdaBoost 테스트데이터 점수 : {}'.format(abc.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0e458390-c19c-48bf-83ed-9c78714b1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 일단, AdaboostingClassifier에서 어떤 특성을 중요하게 여겼는지 확인해볼까요?\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(AdaBoostClassifier())\n",
    "pipeline.fit(train_input, train_target)\n",
    "model = pipeline.named_steps['adaboostclassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "ffc655ff-5f6d-4a2f-a357-a1f3cdc1f640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>특성 중요도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>학습 압박도</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자살충동(Y/N)</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공부 만족도</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공부 시간</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금전적 스트레스</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           특성 중요도\n",
       "학습 압박도       0.18\n",
       "자살충동(Y/N)    0.18\n",
       "공부 만족도       0.14\n",
       "공부 시간        0.12\n",
       "금전적 스트레스     0.12"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 특성별 중요도를 체크해보죠.\n",
    "# 학습 압박도와 자살충동유무가 가장 높은 중요성을 가진다고 판단했군요.\n",
    "# 다음은 상위 5개의 중요한 특성을 추출했습니다.\n",
    "pd.DataFrame(\n",
    "    data=model.feature_importances_,\n",
    "    index=['성별', '연령대', '학습 압박도', '공부 만족도', '수면 시간', '식습관', '자살충동(Y/N)', \n",
    "                         '공부 시간', '금전적 스트레스', '정신질환 가족력'],\n",
    "    columns=['특성 중요도']\n",
    ").sort_values(by=['특성 중요도'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e0a7fe36-6dfe-4191-9ca4-f45c5df27187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 딥러닝 모델로 구현해볼까요?\n",
    "# 제가 가지고 있는 총 특성이 10개죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "11a2b782-3012-499e-9141-a293a343b8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "7f26f0a8-f352-422f-b3b2-950a24cd898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6be7716f-2508-4110-a102-ca4e3824085a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "c244885c-5d0e-4fa6-b672-d8f886379f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7531172037124634)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "b7e78714-3e11-4b72-9402-d75f50ae1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 데이터가 모자라서 그러는게 아닐까요?\n",
    "train_data = student_data[['성별', '연령대', '학습 압박도', '공부 만족도', '수면 시간', '식습관', '자살충동(Y/N)', \n",
    "                         '공부 시간', '금전적 스트레스', '정신질환 가족력']].to_numpy()\n",
    "target_data = student_data['우울증'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "870f1593-5a22-4df4-8be5-b147df05945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(train_data,\n",
    "                                                                      target_data,\n",
    "                                                                      test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "124235cf-a02f-4c85-961f-8c4bb30e3f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "a32b0083-a2da-4391-8bf6-bf1ac0a5744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(test_input, test_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "854e0a47-6f8d-416a-98c9-cbf7ec5ecde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6882793307304382)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(hisotry.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "fff8f028-81b4-4a96-b3c1-c73733cf3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흠.. 데이터가 부족한건 아니군요..\n",
    "train_input, val_input, train_target, val_target = train_test_split(train_input,\n",
    "                                                                    train_target,\n",
    "                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "cbcc486f-eb28-4c02-9342-0292ea5557ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4907 - loss: 1.4166 - val_accuracy: 0.5062 - val_loss: 1.1071\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.9913 - val_accuracy: 0.4938 - val_loss: 0.9421\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4683 - loss: 0.8612 - val_accuracy: 0.4815 - val_loss: 0.8724\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4509 - loss: 0.8242 - val_accuracy: 0.4444 - val_loss: 0.8256\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4157 - loss: 0.8122 - val_accuracy: 0.4568 - val_loss: 0.7913\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4431 - loss: 0.7678 - val_accuracy: 0.4691 - val_loss: 0.7567\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4768 - loss: 0.7291 - val_accuracy: 0.4938 - val_loss: 0.7298\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6939 - val_accuracy: 0.5185 - val_loss: 0.7036\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.6817 - val_accuracy: 0.6049 - val_loss: 0.6761\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.6387 - val_accuracy: 0.6420 - val_loss: 0.6457\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.6232 - val_accuracy: 0.7037 - val_loss: 0.6144\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.5843 - val_accuracy: 0.7160 - val_loss: 0.5869\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5675 - val_accuracy: 0.7654 - val_loss: 0.5621\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.5462 - val_accuracy: 0.7778 - val_loss: 0.5433\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.5008 - val_accuracy: 0.7778 - val_loss: 0.5224\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.5100 - val_accuracy: 0.8025 - val_loss: 0.5072\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4712 - val_accuracy: 0.8272 - val_loss: 0.4899\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.4748 - val_accuracy: 0.8148 - val_loss: 0.4762\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.4665 - val_accuracy: 0.8519 - val_loss: 0.4667\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4405 - val_accuracy: 0.8519 - val_loss: 0.4499\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.4156 - val_accuracy: 0.8765 - val_loss: 0.4374\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8572 - loss: 0.4228 - val_accuracy: 0.8889 - val_loss: 0.4266\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.4303 - val_accuracy: 0.8765 - val_loss: 0.4235\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.4219 - val_accuracy: 0.8889 - val_loss: 0.4103\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3993 - val_accuracy: 0.8889 - val_loss: 0.3950\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.3698 - val_accuracy: 0.9136 - val_loss: 0.3832\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.3782 - val_accuracy: 0.9012 - val_loss: 0.3757\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3512 - val_accuracy: 0.8765 - val_loss: 0.3738\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3688 - val_accuracy: 0.9012 - val_loss: 0.3608\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3456 - val_accuracy: 0.8889 - val_loss: 0.3591\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.3621 - val_accuracy: 0.9012 - val_loss: 0.3463\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.3101 - val_accuracy: 0.9383 - val_loss: 0.3380\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3233 - val_accuracy: 0.9136 - val_loss: 0.3344\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.3298 - val_accuracy: 0.9259 - val_loss: 0.3286\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.3130 - val_accuracy: 0.8765 - val_loss: 0.3332\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2828 - val_accuracy: 0.9383 - val_loss: 0.3158\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.3043 - val_accuracy: 0.9383 - val_loss: 0.3121\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.3047 - val_accuracy: 0.9259 - val_loss: 0.3067\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2639 - val_accuracy: 0.9506 - val_loss: 0.3020\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2721 - val_accuracy: 0.9383 - val_loss: 0.2915\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2620 - val_accuracy: 0.8889 - val_loss: 0.3043\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2745 - val_accuracy: 0.8889 - val_loss: 0.2905\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2815 - val_accuracy: 0.9136 - val_loss: 0.2848\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2403 - val_accuracy: 0.9259 - val_loss: 0.2767\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2544 - val_accuracy: 0.9383 - val_loss: 0.2677\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2740 - val_accuracy: 0.9383 - val_loss: 0.2723\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2349 - val_accuracy: 0.9383 - val_loss: 0.2603\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2511 - val_accuracy: 0.9383 - val_loss: 0.2573\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2465 - val_accuracy: 0.9506 - val_loss: 0.2512\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2368 - val_accuracy: 0.9136 - val_loss: 0.2603\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2553 - val_accuracy: 0.9506 - val_loss: 0.2489\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2615 - val_accuracy: 0.9506 - val_loss: 0.2422\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1932 - val_accuracy: 0.9136 - val_loss: 0.2583\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.2147 - val_accuracy: 0.9383 - val_loss: 0.2451\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2274 - val_accuracy: 0.9506 - val_loss: 0.2349\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2298 - val_accuracy: 0.9383 - val_loss: 0.2295\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2223 - val_accuracy: 0.9259 - val_loss: 0.2483\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.2478 - val_accuracy: 0.9506 - val_loss: 0.2304\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1999 - val_accuracy: 0.9506 - val_loss: 0.2223\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1891 - val_accuracy: 0.9506 - val_loss: 0.2203\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1821 - val_accuracy: 0.9506 - val_loss: 0.2220\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2072 - val_accuracy: 0.9506 - val_loss: 0.2168\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2043 - val_accuracy: 0.9383 - val_loss: 0.2222\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.1959 - val_accuracy: 0.9383 - val_loss: 0.2159\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1744 - val_accuracy: 0.9506 - val_loss: 0.2088\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1777 - val_accuracy: 0.9506 - val_loss: 0.2066\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1875 - val_accuracy: 0.9383 - val_loss: 0.2117\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2147 - val_accuracy: 0.9259 - val_loss: 0.2322\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.1832 - val_accuracy: 0.9383 - val_loss: 0.2053\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2081 - val_accuracy: 0.9383 - val_loss: 0.2108\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.1959 - val_accuracy: 0.9383 - val_loss: 0.2032\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1742 - val_accuracy: 0.9383 - val_loss: 0.2011\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1716 - val_accuracy: 0.9259 - val_loss: 0.2106\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1721 - val_accuracy: 0.9383 - val_loss: 0.1971\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1837 - val_accuracy: 0.9259 - val_loss: 0.2135\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1629 - val_accuracy: 0.9383 - val_loss: 0.1944\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1813 - val_accuracy: 0.9383 - val_loss: 0.1946\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1812 - val_accuracy: 0.9383 - val_loss: 0.1904\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1927 - val_accuracy: 0.9383 - val_loss: 0.2003\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1582 - val_accuracy: 0.9383 - val_loss: 0.1907\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1663 - val_accuracy: 0.9259 - val_loss: 0.2034\n"
     ]
    }
   ],
   "source": [
    "# 모델을 개선해야할 필요가 있겠네요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "5758bd95-b79f-47db-9176-5486379a1bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4951 - loss: 0.7108 - val_accuracy: 0.5062 - val_loss: 0.6941\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6961 - val_accuracy: 0.5062 - val_loss: 0.6914\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5258 - loss: 0.6908 - val_accuracy: 0.5062 - val_loss: 0.6894\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4754 - loss: 0.7129 - val_accuracy: 0.5062 - val_loss: 0.6877\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6823 - val_accuracy: 0.5062 - val_loss: 0.6862\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 0.6875 - val_accuracy: 0.5062 - val_loss: 0.6849\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5090 - loss: 0.6881 - val_accuracy: 0.5062 - val_loss: 0.6837\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5048 - loss: 0.6941 - val_accuracy: 0.5185 - val_loss: 0.6826\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4807 - loss: 0.7042 - val_accuracy: 0.5185 - val_loss: 0.6815\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6758 - val_accuracy: 0.5185 - val_loss: 0.6806\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5235 - loss: 0.6812 - val_accuracy: 0.5185 - val_loss: 0.6796\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.6745 - val_accuracy: 0.5185 - val_loss: 0.6787\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5087 - loss: 0.6782 - val_accuracy: 0.5185 - val_loss: 0.6779\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 0.6840 - val_accuracy: 0.5185 - val_loss: 0.6771\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5380 - loss: 0.6670 - val_accuracy: 0.5185 - val_loss: 0.6763\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.6769 - val_accuracy: 0.5185 - val_loss: 0.6756\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6603 - val_accuracy: 0.5185 - val_loss: 0.6749\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4881 - loss: 0.6996 - val_accuracy: 0.5185 - val_loss: 0.6742\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5221 - loss: 0.6691 - val_accuracy: 0.5185 - val_loss: 0.6736\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6704 - val_accuracy: 0.5185 - val_loss: 0.6729\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4929 - loss: 0.6814 - val_accuracy: 0.5185 - val_loss: 0.6723\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4879 - loss: 0.6871 - val_accuracy: 0.5185 - val_loss: 0.6718\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5340 - loss: 0.6695 - val_accuracy: 0.5185 - val_loss: 0.6712\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5210 - loss: 0.6726 - val_accuracy: 0.5185 - val_loss: 0.6707\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5281 - loss: 0.6616 - val_accuracy: 0.5185 - val_loss: 0.6701\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.6719 - val_accuracy: 0.5185 - val_loss: 0.6696\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5287 - loss: 0.6579 - val_accuracy: 0.5185 - val_loss: 0.6691\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 0.6576 - val_accuracy: 0.5185 - val_loss: 0.6686\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 0.6663 - val_accuracy: 0.5185 - val_loss: 0.6681\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4946 - loss: 0.6796 - val_accuracy: 0.5185 - val_loss: 0.6677\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6671 - val_accuracy: 0.5185 - val_loss: 0.6671\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4980 - loss: 0.6741 - val_accuracy: 0.5185 - val_loss: 0.6666\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6607 - val_accuracy: 0.5185 - val_loss: 0.6661\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6633 - val_accuracy: 0.5185 - val_loss: 0.6656\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6526 - val_accuracy: 0.5185 - val_loss: 0.6652\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.6625 - val_accuracy: 0.5185 - val_loss: 0.6647\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 0.6576 - val_accuracy: 0.5185 - val_loss: 0.6642\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5370 - loss: 0.6542 - val_accuracy: 0.5185 - val_loss: 0.6638\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5521 - loss: 0.6469 - val_accuracy: 0.5185 - val_loss: 0.6634\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5190 - loss: 0.6627 - val_accuracy: 0.5185 - val_loss: 0.6629\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.6519 - val_accuracy: 0.5185 - val_loss: 0.6625\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5389 - loss: 0.6532 - val_accuracy: 0.5185 - val_loss: 0.6621\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5373 - loss: 0.6513 - val_accuracy: 0.5185 - val_loss: 0.6617\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5516 - loss: 0.6431 - val_accuracy: 0.5185 - val_loss: 0.6612\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5083 - loss: 0.6682 - val_accuracy: 0.5309 - val_loss: 0.6609\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5345 - loss: 0.6511 - val_accuracy: 0.5309 - val_loss: 0.6605\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6579 - val_accuracy: 0.5309 - val_loss: 0.6601\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 0.6425 - val_accuracy: 0.5309 - val_loss: 0.6597\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5437 - loss: 0.6567 - val_accuracy: 0.5309 - val_loss: 0.6593\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 0.6571 - val_accuracy: 0.5309 - val_loss: 0.6589\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.6593 - val_accuracy: 0.5432 - val_loss: 0.6585\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4935 - loss: 0.6680 - val_accuracy: 0.5432 - val_loss: 0.6582\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5615 - loss: 0.6409 - val_accuracy: 0.5432 - val_loss: 0.6578\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5329 - loss: 0.6590 - val_accuracy: 0.5432 - val_loss: 0.6575\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5423 - loss: 0.6423 - val_accuracy: 0.5432 - val_loss: 0.6572\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 0.6384 - val_accuracy: 0.5432 - val_loss: 0.6569\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5326 - loss: 0.6492 - val_accuracy: 0.5432 - val_loss: 0.6565\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4901 - loss: 0.6692 - val_accuracy: 0.5432 - val_loss: 0.6562\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5249 - loss: 0.6482 - val_accuracy: 0.5432 - val_loss: 0.6559\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5258 - loss: 0.6513 - val_accuracy: 0.5432 - val_loss: 0.6556\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 0.6363 - val_accuracy: 0.5432 - val_loss: 0.6553\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4950 - loss: 0.6639 - val_accuracy: 0.5432 - val_loss: 0.6550\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.6343 - val_accuracy: 0.5432 - val_loss: 0.6547\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6367 - val_accuracy: 0.5432 - val_loss: 0.6545\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 0.6358 - val_accuracy: 0.5432 - val_loss: 0.6542\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5287 - loss: 0.6512 - val_accuracy: 0.5432 - val_loss: 0.6539\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.6221 - val_accuracy: 0.5432 - val_loss: 0.6536\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 0.6461 - val_accuracy: 0.5432 - val_loss: 0.6533\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5228 - loss: 0.6477 - val_accuracy: 0.5432 - val_loss: 0.6530\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.6408 - val_accuracy: 0.5432 - val_loss: 0.6528\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.6320 - val_accuracy: 0.5432 - val_loss: 0.6525\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5407 - loss: 0.6452 - val_accuracy: 0.5432 - val_loss: 0.6522\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5451 - loss: 0.6462 - val_accuracy: 0.5432 - val_loss: 0.6520\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5479 - loss: 0.6388 - val_accuracy: 0.5432 - val_loss: 0.6517\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4643 - loss: 0.6735 - val_accuracy: 0.5432 - val_loss: 0.6514\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5518 - loss: 0.6427 - val_accuracy: 0.5432 - val_loss: 0.6512\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5364 - loss: 0.6447 - val_accuracy: 0.5432 - val_loss: 0.6509\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5378 - loss: 0.6428 - val_accuracy: 0.5432 - val_loss: 0.6506\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5555 - loss: 0.6368 - val_accuracy: 0.5432 - val_loss: 0.6504\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6381 - val_accuracy: 0.5432 - val_loss: 0.6501\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 0.6505 - val_accuracy: 0.5432 - val_loss: 0.6499\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5722 - loss: 0.6304 - val_accuracy: 0.5432 - val_loss: 0.6496\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.6370 - val_accuracy: 0.5556 - val_loss: 0.6493\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6532 - val_accuracy: 0.5556 - val_loss: 0.6491\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5393 - loss: 0.6405 - val_accuracy: 0.5556 - val_loss: 0.6488\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5687 - loss: 0.6415 - val_accuracy: 0.5556 - val_loss: 0.6486\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5569 - loss: 0.6451 - val_accuracy: 0.5556 - val_loss: 0.6483\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 0.6294 - val_accuracy: 0.5556 - val_loss: 0.6481\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5494 - loss: 0.6426 - val_accuracy: 0.5556 - val_loss: 0.6478\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.6257 - val_accuracy: 0.5556 - val_loss: 0.6476\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.6275 - val_accuracy: 0.5556 - val_loss: 0.6473\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 0.6427 - val_accuracy: 0.5556 - val_loss: 0.6471\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5693 - loss: 0.6310 - val_accuracy: 0.5556 - val_loss: 0.6469\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.6207 - val_accuracy: 0.5556 - val_loss: 0.6466\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 0.6395 - val_accuracy: 0.5556 - val_loss: 0.6464\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 0.6221 - val_accuracy: 0.5556 - val_loss: 0.6462\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 0.6359 - val_accuracy: 0.5556 - val_loss: 0.6459\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 0.6453 - val_accuracy: 0.5556 - val_loss: 0.6457\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5655 - loss: 0.6368 - val_accuracy: 0.5556 - val_loss: 0.6454\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.6491 - val_accuracy: 0.5556 - val_loss: 0.6452\n"
     ]
    }
   ],
   "source": [
    "# Adam 보다는 RMSPROP가 더 좋은 성능을 출력하네요.\n",
    "# Adagrad는 좀 아닌 것 같네요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adagrad(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c9830b7e-2b96-492c-87f8-f45211af4622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7578 - loss: 0.590771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6614 - loss: 0.6404 - val_accuracy: 0.6790 - val_loss: 0.6242\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.6469 - val_accuracy: 0.7037 - val_loss: 0.6195\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6083 - val_accuracy: 0.6790 - val_loss: 0.6107\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.6047 - val_accuracy: 0.6667 - val_loss: 0.6039\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.5832 - val_accuracy: 0.6790 - val_loss: 0.5955\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.5875 - val_accuracy: 0.7037 - val_loss: 0.5894\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.5626 - val_accuracy: 0.7160 - val_loss: 0.5820\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5588 - val_accuracy: 0.7531 - val_loss: 0.5694\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.5386 - val_accuracy: 0.7531 - val_loss: 0.5622\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.5299 - val_accuracy: 0.7531 - val_loss: 0.5551\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.5219 - val_accuracy: 0.7901 - val_loss: 0.5463\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.5077 - val_accuracy: 0.7407 - val_loss: 0.5325\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.4887 - val_accuracy: 0.7284 - val_loss: 0.5236\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4911 - val_accuracy: 0.7901 - val_loss: 0.5131\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.4954 - val_accuracy: 0.8272 - val_loss: 0.5024\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.4622 - val_accuracy: 0.7284 - val_loss: 0.5021\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.4718 - val_accuracy: 0.8272 - val_loss: 0.4924\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.4812 - val_accuracy: 0.8395 - val_loss: 0.4831\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4532 - val_accuracy: 0.7531 - val_loss: 0.4854\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4332 - val_accuracy: 0.8395 - val_loss: 0.4690\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4380 - val_accuracy: 0.7654 - val_loss: 0.4637\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7848 - loss: 0.4593 - val_accuracy: 0.8395 - val_loss: 0.4572\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.4560 - val_accuracy: 0.8272 - val_loss: 0.4516\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4219 - val_accuracy: 0.8272 - val_loss: 0.4456\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4633 - val_accuracy: 0.7901 - val_loss: 0.4416\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4263 - val_accuracy: 0.8519 - val_loss: 0.4353\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4360 - val_accuracy: 0.7901 - val_loss: 0.4390\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4294 - val_accuracy: 0.7901 - val_loss: 0.4302\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4064 - val_accuracy: 0.8519 - val_loss: 0.4271\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.4354 - val_accuracy: 0.8519 - val_loss: 0.4163\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3852 - val_accuracy: 0.8765 - val_loss: 0.4165\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.3839 - val_accuracy: 0.8765 - val_loss: 0.4098\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3996 - val_accuracy: 0.8765 - val_loss: 0.4050\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.4063 - val_accuracy: 0.8642 - val_loss: 0.4009\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.3843 - val_accuracy: 0.8765 - val_loss: 0.3969\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3684 - val_accuracy: 0.8765 - val_loss: 0.3937\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3783 - val_accuracy: 0.8765 - val_loss: 0.3903\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.3738 - val_accuracy: 0.8642 - val_loss: 0.3871\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3810 - val_accuracy: 0.8765 - val_loss: 0.3822\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3748 - val_accuracy: 0.8889 - val_loss: 0.3774\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8639 - loss: 0.3503 - val_accuracy: 0.8765 - val_loss: 0.3741\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3491 - val_accuracy: 0.8765 - val_loss: 0.3791\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3826 - val_accuracy: 0.8765 - val_loss: 0.3700\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3260 - val_accuracy: 0.8765 - val_loss: 0.3743\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3673 - val_accuracy: 0.8765 - val_loss: 0.3595\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3433 - val_accuracy: 0.8889 - val_loss: 0.3600\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3495 - val_accuracy: 0.8889 - val_loss: 0.3516\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3295 - val_accuracy: 0.8889 - val_loss: 0.3491\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8412 - loss: 0.3625 - val_accuracy: 0.9012 - val_loss: 0.3474\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3475 - val_accuracy: 0.8642 - val_loss: 0.3465\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3399 - val_accuracy: 0.8395 - val_loss: 0.3614\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3674 - val_accuracy: 0.8889 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3340 - val_accuracy: 0.9012 - val_loss: 0.3310\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.3044 - val_accuracy: 0.9012 - val_loss: 0.3281\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.3228 - val_accuracy: 0.9012 - val_loss: 0.3260\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3347 - val_accuracy: 0.8765 - val_loss: 0.3313\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.3166 - val_accuracy: 0.8765 - val_loss: 0.3380\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.3235 - val_accuracy: 0.8765 - val_loss: 0.3234\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2864 - val_accuracy: 0.8889 - val_loss: 0.3212\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2885 - val_accuracy: 0.9259 - val_loss: 0.3119\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.2857 - val_accuracy: 0.9136 - val_loss: 0.3102\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3299 - val_accuracy: 0.9259 - val_loss: 0.3083\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3099 - val_accuracy: 0.8889 - val_loss: 0.3130\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2945 - val_accuracy: 0.9259 - val_loss: 0.3018\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.3058 - val_accuracy: 0.8889 - val_loss: 0.3167\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3127 - val_accuracy: 0.9012 - val_loss: 0.3119\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3027 - val_accuracy: 0.9012 - val_loss: 0.3144\n"
     ]
    }
   ],
   "source": [
    "# 모델을 개선해야할 필요가 있겠네요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.SGD(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "b216d073-aa1e-4434-8cc7-29747522ad70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4586 - loss: 1.0703 - val_accuracy: 0.4074 - val_loss: 0.8488\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: 0.7809 - val_accuracy: 0.4815 - val_loss: 0.7243\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5539 - loss: 0.6836 - val_accuracy: 0.5556 - val_loss: 0.6780\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.6646 - val_accuracy: 0.6296 - val_loss: 0.6539\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6309 - loss: 0.6201 - val_accuracy: 0.6173 - val_loss: 0.6318\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.6225 - val_accuracy: 0.6296 - val_loss: 0.6133\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.5890 - val_accuracy: 0.6790 - val_loss: 0.5940\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.5751 - val_accuracy: 0.7037 - val_loss: 0.5744\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.5463 - val_accuracy: 0.7654 - val_loss: 0.5546\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5512 - val_accuracy: 0.7901 - val_loss: 0.5348\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.5011 - val_accuracy: 0.7901 - val_loss: 0.5175\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4695 - val_accuracy: 0.7901 - val_loss: 0.5019\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4937 - val_accuracy: 0.8025 - val_loss: 0.4847\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.4468 - val_accuracy: 0.8272 - val_loss: 0.4694\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4347 - val_accuracy: 0.8272 - val_loss: 0.4547\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.4189 - val_accuracy: 0.8272 - val_loss: 0.4424\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.4036 - val_accuracy: 0.8519 - val_loss: 0.4293\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4104 - val_accuracy: 0.8272 - val_loss: 0.4177\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3854 - val_accuracy: 0.8642 - val_loss: 0.4066\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.3685 - val_accuracy: 0.8519 - val_loss: 0.3954\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3521 - val_accuracy: 0.8519 - val_loss: 0.3848\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3704 - val_accuracy: 0.8395 - val_loss: 0.3756\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3512 - val_accuracy: 0.8395 - val_loss: 0.3653\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.3553 - val_accuracy: 0.8642 - val_loss: 0.3588\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.3134 - val_accuracy: 0.8765 - val_loss: 0.3465\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.3448 - val_accuracy: 0.8889 - val_loss: 0.3385\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2949 - val_accuracy: 0.8519 - val_loss: 0.3346\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2909 - val_accuracy: 0.8765 - val_loss: 0.3233\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2707 - val_accuracy: 0.8642 - val_loss: 0.3188\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2760 - val_accuracy: 0.8642 - val_loss: 0.3161\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2686 - val_accuracy: 0.8642 - val_loss: 0.3057\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2754 - val_accuracy: 0.9012 - val_loss: 0.2978\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2554 - val_accuracy: 0.8519 - val_loss: 0.3030\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.2722 - val_accuracy: 0.8519 - val_loss: 0.2971\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.2634 - val_accuracy: 0.9012 - val_loss: 0.2824\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2492 - val_accuracy: 0.8519 - val_loss: 0.2839\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.2511 - val_accuracy: 0.8519 - val_loss: 0.2880\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2397 - val_accuracy: 0.8765 - val_loss: 0.2737\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2526 - val_accuracy: 0.9136 - val_loss: 0.2646\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2492 - val_accuracy: 0.9012 - val_loss: 0.2613\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2274 - val_accuracy: 0.8395 - val_loss: 0.2769\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2456 - val_accuracy: 0.8765 - val_loss: 0.2640\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2135 - val_accuracy: 0.9012 - val_loss: 0.2525\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2231 - val_accuracy: 0.8889 - val_loss: 0.2576\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1842 - val_accuracy: 0.8889 - val_loss: 0.2510\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2328 - val_accuracy: 0.8889 - val_loss: 0.2580\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.2086 - val_accuracy: 0.9012 - val_loss: 0.2383\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.1914 - val_accuracy: 0.9012 - val_loss: 0.2363\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2084 - val_accuracy: 0.9012 - val_loss: 0.2396\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.1862 - val_accuracy: 0.8889 - val_loss: 0.2390\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2104 - val_accuracy: 0.9012 - val_loss: 0.2323\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2077 - val_accuracy: 0.9012 - val_loss: 0.2280\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.1958 - val_accuracy: 0.9012 - val_loss: 0.2257\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.1791 - val_accuracy: 0.9136 - val_loss: 0.2228\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1778 - val_accuracy: 0.9012 - val_loss: 0.2315\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.1923 - val_accuracy: 0.9012 - val_loss: 0.2267\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1731 - val_accuracy: 0.9012 - val_loss: 0.2254\n"
     ]
    }
   ],
   "source": [
    "# 지금까지 옵티마이저를 바꾼 결과 RMSPROP가 가장 적절하다는 것을 알았는데, 혹시 점수가 몇점인가요?\n",
    "# 모델을 개선해야할 필요가 있겠네요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(10,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "hisotry = model.fit(train_input,\n",
    "                    train_target,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "4d0b2afb-07f9-4260-876b-4ca0cf1659b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝을 사용하는 것 보다, 머신러닝의 모델을 사용하는 것이 점수가 더 좋다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "27f105fb-aace-4fec-bf4f-51cd6850b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('RMSPROP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "39ba90f6-6c6e-42bb-800e-8f4e9363b0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost 훈련점수 : 0.978125\n",
      "Adaboost 검증점수 : 0.9382716049382716\n",
      "Adaboost 테스트점수 : 0.9603960396039604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hack/Develop/Git/real_virtual/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "abc.fit(train_input, train_target)\n",
    "print('Adaboost 훈련점수 : {}'.format(abc.score(train_input, train_target)))\n",
    "print('Adaboost 검증점수 : {}'.format(abc.score(val_input, val_target)))\n",
    "print('Adaboost 테스트점수 : {}'.format(abc.score(test_input, test_target)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
